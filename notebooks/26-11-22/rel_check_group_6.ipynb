{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for relationships between entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum performance that the model with word vectors was **Accuracy of 92.8 with a weighted F1-Score of 0.92.**\n",
    "\n",
    "The Random Forest Model with TF-IDF yields an **Accuracy of 87.3 with a weighted F1-Score of 0.85.** In the unseen test set we can see that the model makes good predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imb_Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import spacy\n",
    "from xgboost import XGBClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1180, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_between_orgs</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to a good supply partnership but nothing to wr...</td>\n",
       "      <td>Garbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>, based in</td>\n",
       "      <td>Garbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>, will take a</td>\n",
       "      <td>Garbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>Garbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>project off the coast of</td>\n",
       "      <td>Garbage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text_between_orgs    class\n",
       "0  to a good supply partnership but nothing to wr...  Garbage\n",
       "1                                         , based in  Garbage\n",
       "2                                      , will take a  Garbage\n",
       "3                                                  ,  Garbage\n",
       "4                           project off the coast of  Garbage"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.read_excel(\"partnership_training_data.xlsx\")\n",
    "print(training_set.shape)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_between_orgs    1\n",
       "class                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values:\n",
    "training_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Duplicate entries:\n",
    "training_set.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Garbage                934\n",
       "Partner                 62\n",
       "Joint Venture           62\n",
       "Acquisition             42\n",
       "Merger                  38\n",
       "Investor                21\n",
       "Signed an agreement     12\n",
       "Subsidiary               8\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Class Imbalance\n",
    "training_set[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_set = pd.read_excel(\"partnership_prediction_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_set.drop(\"class\", axis=1)\n",
    "y = training_set[\"class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_between_orgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>sponsors such as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>management infrastructure Vehicle segment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>commenced the production and marketing marketi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>joint venture between</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>, Transport and Tourism . The unit of vertical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text_between_orgs\n",
       "870                                   sponsors such as\n",
       "339          management infrastructure Vehicle segment\n",
       "848  commenced the production and marketing marketi...\n",
       "985                              joint venture between\n",
       "839  , Transport and Tourism . The unit of vertical..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words(\"english\"))\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "y_train = label_enc.fit_transform(y_train)\n",
    "y_test = label_enc.transform(y_test)\n",
    "\n",
    "col_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tfidf_1\", vectorizer, \"text_between_orgs\"),\n",
    "    ]\n",
    ")\n",
    "oversample = RandomOverSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 92.80000000000001\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89         8\n",
      "           1       0.97      0.95      0.96       187\n",
      "           2       0.67      0.50      0.57         4\n",
      "           3       0.85      0.85      0.85        13\n",
      "           4       0.78      0.88      0.82         8\n",
      "           5       0.75      1.00      0.86        12\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.93       236\n",
      "   macro avg       0.73      0.77      0.74       236\n",
      "weighted avg       0.92      0.93      0.92       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1)\n",
    "\n",
    "clf_best = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"prep\", col_transformer),\n",
    "        (\"oversampling\", oversample),\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf_best.fit(X_train, y_train)\n",
    "y_pred = clf_best.predict(X_test)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words(\"english\"))\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "y_train = label_enc.fit_transform(y_train)\n",
    "y_test = label_enc.transform(y_test)\n",
    "\n",
    "col_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tfidf_1\", vectorizer, \"text_between_orgs\"),\n",
    "    ]\n",
    ")\n",
    "oversample = RandomOverSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 91.9\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88         8\n",
      "           1       0.97      0.93      0.95       187\n",
      "           2       0.80      1.00      0.89         4\n",
      "           3       0.79      0.85      0.81        13\n",
      "           4       0.78      0.88      0.82         8\n",
      "           5       0.67      1.00      0.80        12\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.92       236\n",
      "   macro avg       0.73      0.82      0.77       236\n",
      "weighted avg       0.93      0.92      0.92       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0, solver=\"liblinear\", C=10)\n",
    "\n",
    "clf = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"prep\", col_transformer),\n",
    "        (\"oversampling\", oversample),\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using word vectors|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "# Remove Stopwords from train and test\n",
    "f = 'text_between_orgs'\n",
    "train_texts = [' '.join([t for t in text.split() if(t.lower() not in stop_words)]) for text in X_train[f]]\n",
    "test_texts = [' '.join([t for t in text.split() if(t.lower() not in stop_words)]) for text in X_test[f]]\n",
    "\n",
    "# Get dataframes with text converted to spaCy vectors\n",
    "tr_df = pd.DataFrame([list(nlp(text).vector) for text in train_texts])\n",
    "te_df = pd.DataFrame([list(nlp(text).vector) for text in test_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 87.3\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77         8\n",
      "           1       0.87      0.99      0.93       187\n",
      "           2       1.00      0.25      0.40         4\n",
      "           3       0.86      0.46      0.60        13\n",
      "           4       0.67      0.25      0.36         8\n",
      "           5       1.00      0.50      0.67        12\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.87       236\n",
      "   macro avg       0.80      0.45      0.55       236\n",
      "weighted avg       0.87      0.87      0.85       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler(random_state=0)\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "clf = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"oversampling\", oversample),\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf.fit(tr_df, y_train)\n",
    "y_pred = clf.predict(te_df)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "# Remove Stopwords from train and test\n",
    "f = 'text_between_orgs'\n",
    "train_texts = [' '.join([t for t in text.split() if(t.lower() not in stop_words)]) for text in X_train[f]]\n",
    "test_texts = [' '.join([t for t in text.split() if(t.lower() not in stop_words)]) for text in X_test[f]]\n",
    "\n",
    "# Get dataframes with text converted to spaCy vectors\n",
    "tr_df = pd.DataFrame([list(nlp(text).vector) for text in train_texts])\n",
    "te_df = pd.DataFrame([list(nlp(text).vector) for text in test_texts])\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "y_train = label_enc.fit_transform(y_train)\n",
    "y_test = label_enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 87.3\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77         8\n",
      "           1       0.87      0.99      0.93       187\n",
      "           2       1.00      0.25      0.40         4\n",
      "           3       0.86      0.46      0.60        13\n",
      "           4       0.67      0.25      0.36         8\n",
      "           5       1.00      0.50      0.67        12\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.87       236\n",
      "   macro avg       0.80      0.45      0.55       236\n",
      "weighted avg       0.87      0.87      0.85       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler(random_state=0)\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "clf = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"oversampling\", oversample),\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf.fit(tr_df, y_train)\n",
    "y_pred = clf.predict(te_df)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check using Prediction set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_check = pred_set[['Predicate']]\n",
    "col_check.columns = ['text_between_orgs']\n",
    "pred_set[\"Predicted_class\"] = clf_best.predict(col_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_set.Predicted_class = pred_set.Predicted_class.map(\n",
    "    {\n",
    "        0: \"Acquisition\",\n",
    "        1: \"Garbage\",\n",
    "        2: \"Investor\",\n",
    "        3: \"Joint Venture\",\n",
    "        4: \"Merger\",\n",
    "        5: \"Partner\",\n",
    "        6: \"Signed an agreement\",\n",
    "        7: \"Subsidiary\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Predicate</th>\n",
       "      <th>Entity_2</th>\n",
       "      <th>Predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spirit Energy</td>\n",
       "      <td>has agreed to partner with</td>\n",
       "      <td>Neptune Energy</td>\n",
       "      <td>Partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air Products</td>\n",
       "      <td>joint venture in India , called</td>\n",
       "      <td>INOX Air Products</td>\n",
       "      <td>Joint Venture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air Products</td>\n",
       "      <td>acquired a 50 % equity stake in</td>\n",
       "      <td>Industrial Oxygen Company Ltd</td>\n",
       "      <td>Acquisition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ares Management Corporation</td>\n",
       "      <td>announced that a subsidiary of</td>\n",
       "      <td>Ares</td>\n",
       "      <td>Subsidiary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ares</td>\n",
       "      <td>has entered into a definitive agreement with a...</td>\n",
       "      <td>BrightSphere Investment Group</td>\n",
       "      <td>Subsidiary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Landmark Investment Holdings LP</td>\n",
       "      <td>to acquire 100 % of</td>\n",
       "      <td>Landmark Partners</td>\n",
       "      <td>Garbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Conagra Brands</td>\n",
       "      <td>will acquire all outstanding shares of</td>\n",
       "      <td>Pinnacle Foods</td>\n",
       "      <td>Garbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>, in partnership with</td>\n",
       "      <td>Santander Bank</td>\n",
       "      <td>Partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fifth Street Finance</td>\n",
       "      <td>announced that its</td>\n",
       "      <td>the Board of Directors</td>\n",
       "      <td>Acquisition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IronPlanet</td>\n",
       "      <td>® jointly announced that they have entered int...</td>\n",
       "      <td>Ritchie Bros</td>\n",
       "      <td>Joint Venture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Entity  \\\n",
       "0                    Spirit Energy   \n",
       "1                     Air Products   \n",
       "2                     Air Products   \n",
       "3      Ares Management Corporation   \n",
       "4                             Ares   \n",
       "5  Landmark Investment Holdings LP   \n",
       "6                   Conagra Brands   \n",
       "7                    Goldman Sachs   \n",
       "8             Fifth Street Finance   \n",
       "9                       IronPlanet   \n",
       "\n",
       "                                           Predicate  \\\n",
       "0                         has agreed to partner with   \n",
       "1                    joint venture in India , called   \n",
       "2                    acquired a 50 % equity stake in   \n",
       "3                     announced that a subsidiary of   \n",
       "4  has entered into a definitive agreement with a...   \n",
       "5                                to acquire 100 % of   \n",
       "6             will acquire all outstanding shares of   \n",
       "7                              , in partnership with   \n",
       "8                                 announced that its   \n",
       "9  ® jointly announced that they have entered int...   \n",
       "\n",
       "                        Entity_2 Predicted_class  \n",
       "0                 Neptune Energy         Partner  \n",
       "1              INOX Air Products   Joint Venture  \n",
       "2  Industrial Oxygen Company Ltd     Acquisition  \n",
       "3                           Ares      Subsidiary  \n",
       "4  BrightSphere Investment Group      Subsidiary  \n",
       "5              Landmark Partners         Garbage  \n",
       "6                 Pinnacle Foods         Garbage  \n",
       "7                 Santander Bank         Partner  \n",
       "8         the Board of Directors     Acquisition  \n",
       "9                   Ritchie Bros   Joint Venture  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum performance that the model with word vectors was **Accuracy of 92.8 with a weighted F1-Score of 0.92.**\n",
    "\n",
    "The Random Forest Model with TF-IDF yields an **Accuracy of 87.3 with a weighted F1-Score of 0.85.** In the unseem test set we can see that the model makes good predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8239ba0ff96be68a749984a1d0f0fdb6158c4e27c47b22616c2f5e2eb3d022cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
