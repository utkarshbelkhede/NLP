{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Importing Gensim\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(\"risk_articles.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Companies</th>\n",
       "      <th>Search Query</th>\n",
       "      <th>url</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk Terms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layoffs</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>Layoffs Twitter</td>\n",
       "      <td>https://fortune.com/2022/11/18/twitter-former-...</td>\n",
       "      <td>When Twitter’s new owner, Elon Musk, decided t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layoffs</th>\n",
       "      <td>Meta</td>\n",
       "      <td>Layoffs Meta</td>\n",
       "      <td>https://about.fb.com/news/2022/11/mark-zuckerb...</td>\n",
       "      <td>Mark Zuckerberg just shared the following with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layoffs</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Layoffs Amazon</td>\n",
       "      <td>https://economictimes.indiatimes.com/news/inte...</td>\n",
       "      <td>The mass layoffs that began in Amazon 's corpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sexual Harrassment</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>Sexual Harrassment Twitter</td>\n",
       "      <td>https://twitter.com/hashtag/sexualharassment</td>\n",
       "      <td>JavaScript is not available.\\n\\nWe’ve detected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sexual Harrassment</th>\n",
       "      <td>Meta</td>\n",
       "      <td>Sexual Harrassment Meta</td>\n",
       "      <td>https://nypost.com/2022/05/27/women-are-being-...</td>\n",
       "      <td>Disturbing accounts of women being sexually as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Companies                Search Query  \\\n",
       "Risk Terms                                                 \n",
       "Layoffs              Twitter             Layoffs Twitter   \n",
       "Layoffs                 Meta                Layoffs Meta   \n",
       "Layoffs               Amazon              Layoffs Amazon   \n",
       "Sexual Harrassment   Twitter  Sexual Harrassment Twitter   \n",
       "Sexual Harrassment      Meta     Sexual Harrassment Meta   \n",
       "\n",
       "                                                                  url  \\\n",
       "Risk Terms                                                              \n",
       "Layoffs             https://fortune.com/2022/11/18/twitter-former-...   \n",
       "Layoffs             https://about.fb.com/news/2022/11/mark-zuckerb...   \n",
       "Layoffs             https://economictimes.indiatimes.com/news/inte...   \n",
       "Sexual Harrassment       https://twitter.com/hashtag/sexualharassment   \n",
       "Sexual Harrassment  https://nypost.com/2022/05/27/women-are-being-...   \n",
       "\n",
       "                                                                 Text  \n",
       "Risk Terms                                                             \n",
       "Layoffs             When Twitter’s new owner, Elon Musk, decided t...  \n",
       "Layoffs             Mark Zuckerberg just shared the following with...  \n",
       "Layoffs             The mass layoffs that began in Amazon 's corpo...  \n",
       "Sexual Harrassment  JavaScript is not available.\\n\\nWe’ve detected...  \n",
       "Sexual Harrassment  Disturbing accounts of women being sexually as...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Companies       object\n",
       "Search Query    object\n",
       "url             object\n",
       "Text            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(articles[\"Text\"].astype(str))\n",
    "############## Pre-proc\n",
    "# stop loss words\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "# punctuation\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "# lemmatization\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# One function for all the steps:\n",
    "def clean(doc):\n",
    "\n",
    "    # convert text into lower case + split into words\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "\n",
    "    # remove any stop words present\n",
    "    punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
    "\n",
    "    # remove punctuations + normalize the text\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "\n",
    "# clean data stored in a new list\n",
    "clean_corpus = [clean(doc).split() for doc in corpus]\n",
    "\n",
    "dict_ = corpora.Dictionary(clean_corpus)\n",
    "doc_term_matrix = [dict_.doc2bow(i) for i in clean_corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.004*\"people\" + 0.003*\"we’re\" + 0.003*\"meta\" + 0.003*\"employee\" + 0.003*\"business\"'), (1, '0.009*\"people\" + 0.007*\"company\" + 0.007*\"employee\" + 0.007*\"meta\" + 0.006*\"we’re\"'), (2, '0.007*\"meta\" + 0.007*\"company\" + 0.007*\"people\" + 0.006*\"another\" + 0.005*\"metaverse\"'), (3, '0.008*\"people\" + 0.007*\"we’re\" + 0.006*\"metaverse\" + 0.005*\"i’m\" + 0.005*\"meta\"'), (4, '0.007*\"people\" + 0.006*\"employee\" + 0.005*\"expense\" + 0.005*\"company\" + 0.004*\"work\"'), (5, '0.012*\"company\" + 0.011*\"people\" + 0.011*\"employee\" + 0.010*\"expense\" + 0.006*\"work\"'), (6, '0.017*\"company\" + 0.011*\"people\" + 0.011*\"employee\" + 0.010*\"expense\" + 0.008*\"said\"'), (7, '0.006*\"people\" + 0.006*\"employee\" + 0.006*\"meta\" + 0.006*\"said\" + 0.006*\"company\"'), (8, '0.012*\"fraud\" + 0.010*\"company\" + 0.008*\"year\" + 0.008*\"employee\" + 0.007*\"people\"'), (9, '0.017*\"javascript\" + 0.017*\"browser\" + 0.012*\"supported\" + 0.008*\"help\" + 0.007*\"we’ve\"')]\n"
     ]
    }
   ],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(\n",
    "    doc_term_matrix,\n",
    "    num_topics=10,\n",
    "    id2word=dict_,\n",
    "    passes=1,\n",
    "    random_state=0,\n",
    "    eval_every=None,\n",
    ")\n",
    "ldamodel.print_topics()\n",
    "print(ldamodel.print_topics(num_topics=10, num_words=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc :  0 [(5, 0.9977823)]\n",
      "doc :  1 [(3, 0.97542244), (5, 0.023514185)]\n",
      "doc :  2 [(6, 0.9954065)]\n",
      "doc :  3 [(9, 0.9608687)]\n",
      "doc :  4 [(2, 0.9985517)]\n",
      "doc :  5 [(0, 0.050001524), (1, 0.050001524), (2, 0.050001524), (3, 0.050001524), (4, 0.050001524), (5, 0.050001524), (6, 0.050001524), (7, 0.050001524), (8, 0.5499863), (9, 0.050001524)]\n",
      "doc :  6 [(9, 0.9608687)]\n",
      "doc :  7 [(0, 0.05000152), (1, 0.05000152), (2, 0.05000152), (3, 0.05000152), (4, 0.05000152), (5, 0.05000152), (6, 0.05000152), (7, 0.05000152), (8, 0.5499863), (9, 0.05000152)]\n",
      "doc :  8 [(8, 0.9799988)]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in ldamodel[doc_term_matrix]:\n",
    "    print(\"doc : \", count, i)\n",
    "    count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8239ba0ff96be68a749984a1d0f0fdb6158c4e27c47b22616c2f5e2eb3d022cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
