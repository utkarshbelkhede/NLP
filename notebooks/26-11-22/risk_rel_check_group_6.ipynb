{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for risk relationships between entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all the text columns with separate TF-IDF vectorizers yields an **Accuracy of 0.77 with a weighted F1-Score of 0.76.**. We see a drop in performance when using word vectors as the Accuracy drops to 0.71.\n",
    "\n",
    "After creating new features by extracting the text between the given entities, we see a further drop in performance with the best results reaching only an **Accuracy of 0.61.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imb_Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import spacy\n",
    "from xgboost import XGBClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(498, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>Extracted_Sents</th>\n",
       "      <th>Risks</th>\n",
       "      <th>Organizations</th>\n",
       "      <th>Relationship_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transition phase of corruption?</td>\n",
       "      <td>https://arunachaltimes.in/index.php/2022/10/09...</td>\n",
       "      <td>As per Transparency international, corruption ...</td>\n",
       "      <td>corruption</td>\n",
       "      <td>transparency</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stellantis Faces $300 Million Fine for Emissio...</td>\n",
       "      <td>https://autos.yahoo.com/stellantis-faces-300-m...</td>\n",
       "      <td>Photo credit: is on the hook for up to $300 mi...</td>\n",
       "      <td>criminal charges</td>\n",
       "      <td>fca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stellantis Faces $300 Million Fine for Emissio...</td>\n",
       "      <td>https://autos.yahoo.com/stellantis-faces-300-m...</td>\n",
       "      <td>Photo credit: is on the hook for up to $300 mi...</td>\n",
       "      <td>polluting technologies</td>\n",
       "      <td>fca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stellantis Faces $300 Million Fine for Emissio...</td>\n",
       "      <td>https://autos.yahoo.com/stellantis-faces-300-m...</td>\n",
       "      <td>The automaker pled guilty in June to wire frau...</td>\n",
       "      <td>violating the clean air act</td>\n",
       "      <td>fbi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stellantis Faces $300 Million Fine for Emissio...</td>\n",
       "      <td>https://autos.yahoo.com/stellantis-faces-300-m...</td>\n",
       "      <td>Now, the merged Stellantis group is on the hoo...</td>\n",
       "      <td>fines</td>\n",
       "      <td>stellantis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                    Transition phase of corruption?   \n",
       "1  Stellantis Faces $300 Million Fine for Emissio...   \n",
       "2  Stellantis Faces $300 Million Fine for Emissio...   \n",
       "3  Stellantis Faces $300 Million Fine for Emissio...   \n",
       "4  Stellantis Faces $300 Million Fine for Emissio...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://arunachaltimes.in/index.php/2022/10/09...   \n",
       "1  https://autos.yahoo.com/stellantis-faces-300-m...   \n",
       "2  https://autos.yahoo.com/stellantis-faces-300-m...   \n",
       "3  https://autos.yahoo.com/stellantis-faces-300-m...   \n",
       "4  https://autos.yahoo.com/stellantis-faces-300-m...   \n",
       "\n",
       "                                     Extracted_Sents  \\\n",
       "0  As per Transparency international, corruption ...   \n",
       "1  Photo credit: is on the hook for up to $300 mi...   \n",
       "2  Photo credit: is on the hook for up to $300 mi...   \n",
       "3  The automaker pled guilty in June to wire frau...   \n",
       "4  Now, the merged Stellantis group is on the hoo...   \n",
       "\n",
       "                         Risks Organizations  Relationship_Tag  \n",
       "0                   corruption  transparency                 0  \n",
       "1             criminal charges           fca                 1  \n",
       "2       polluting technologies           fca                 1  \n",
       "3  violating the clean air act           fbi                 0  \n",
       "4                        fines    stellantis                 1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.read_excel(\"risk_rel_data_tagged.xlsx\")\n",
    "print(training_set.shape)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title               0\n",
       "link                0\n",
       "Extracted_Sents     0\n",
       "Risks               0\n",
       "Organizations       0\n",
       "Relationship_Tag    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values:\n",
    "training_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Duplicate entries:\n",
    "training_set.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    273\n",
       "1    225\n",
       "Name: Relationship_Tag, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Class Imbalance\n",
    "training_set[\"Relationship_Tag\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling without feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_set.drop('Relationship_Tag', axis=1)\n",
    "y = training_set['Relationship_Tag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>Extracted_Sents</th>\n",
       "      <th>Risks</th>\n",
       "      <th>Organizations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>How companies handle criminal charges: Trump O...</td>\n",
       "      <td>https://finance.yahoo.com/news/companies-handl...</td>\n",
       "      <td>For example, pharmaceutical companies convicte...</td>\n",
       "      <td>pharmaceutical companies convicted of felonies</td>\n",
       "      <td>medicare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Former CEO of Volkswagen AG Charged with Consp...</td>\n",
       "      <td>https://www.justice.gov/opa/pr/former-ceo-volk...</td>\n",
       "      <td>The indictment further alleges that Winterkorn...</td>\n",
       "      <td>perpetrate the fraud</td>\n",
       "      <td>vw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>FCA guilty in labor corruption scandal as auto...</td>\n",
       "      <td>https://news.yahoo.com/fca-guilty-labor-corrup...</td>\n",
       "      <td>The party included liquor, more than $7,000 wo...</td>\n",
       "      <td>convicted</td>\n",
       "      <td>uaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Stellantis admits guilt to criminal conspiracy...</td>\n",
       "      <td>https://news.yahoo.com/stellantis-admits-guilt...</td>\n",
       "      <td>The company, known then as Fiat Chrysler Autom...</td>\n",
       "      <td>cheating</td>\n",
       "      <td>fiat chrysler automobiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Stellantis Faces $300 Million Fine for Emissio...</td>\n",
       "      <td>https://autos.yahoo.com/stellantis-faces-300-m...</td>\n",
       "      <td>Now, the merged Stellantis group is on the hoo...</td>\n",
       "      <td>pleading guilty</td>\n",
       "      <td>environmental protection agency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "125  How companies handle criminal charges: Trump O...   \n",
       "466  Former CEO of Volkswagen AG Charged with Consp...   \n",
       "270  FCA guilty in labor corruption scandal as auto...   \n",
       "301  Stellantis admits guilt to criminal conspiracy...   \n",
       "18   Stellantis Faces $300 Million Fine for Emissio...   \n",
       "\n",
       "                                                  link  \\\n",
       "125  https://finance.yahoo.com/news/companies-handl...   \n",
       "466  https://www.justice.gov/opa/pr/former-ceo-volk...   \n",
       "270  https://news.yahoo.com/fca-guilty-labor-corrup...   \n",
       "301  https://news.yahoo.com/stellantis-admits-guilt...   \n",
       "18   https://autos.yahoo.com/stellantis-faces-300-m...   \n",
       "\n",
       "                                       Extracted_Sents  \\\n",
       "125  For example, pharmaceutical companies convicte...   \n",
       "466  The indictment further alleges that Winterkorn...   \n",
       "270  The party included liquor, more than $7,000 wo...   \n",
       "301  The company, known then as Fiat Chrysler Autom...   \n",
       "18   Now, the merged Stellantis group is on the hoo...   \n",
       "\n",
       "                                              Risks  \\\n",
       "125  pharmaceutical companies convicted of felonies   \n",
       "466                            perpetrate the fraud   \n",
       "270                                       convicted   \n",
       "301                                        cheating   \n",
       "18                                  pleading guilty   \n",
       "\n",
       "                       Organizations  \n",
       "125                         medicare  \n",
       "466                               vw  \n",
       "270                              uaw  \n",
       "301        fiat chrysler automobiles  \n",
       "18   environmental protection agency  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'link', 'Extracted_Sents', 'Risks', 'Organizations'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125    0\n",
       "466    1\n",
       "270    1\n",
       "301    1\n",
       "18     0\n",
       "      ..\n",
       "177    0\n",
       "453    1\n",
       "422    1\n",
       "437    0\n",
       "124    1\n",
       "Name: Relationship_Tag, Length: 398, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 77.0\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.89      0.81        55\n",
      "           1       0.82      0.62      0.71        45\n",
      "\n",
      "    accuracy                           0.77       100\n",
      "   macro avg       0.78      0.76      0.76       100\n",
      "weighted avg       0.78      0.77      0.76       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer1 = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english')\n",
    "    )\n",
    "vectorizer2 = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english')\n",
    "    )\n",
    "vectorizer3 = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english')\n",
    "    )\n",
    "\n",
    "col_transformer = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"tfidf_1\", vectorizer1, \"Extracted_Sents\"),\n",
    "        (\"tfidf_2\", vectorizer2, \"Risks\"),\n",
    "        (\"tfidf_3\", vectorizer3, \"Organizations\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1)\n",
    "\n",
    "clf_best = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"prep\", col_transformer),\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf_best.fit(X_train, y_train)\n",
    "y_pred = clf_best.predict(X_test)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 76.0\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79        55\n",
      "           1       0.76      0.69      0.72        45\n",
      "\n",
      "    accuracy                           0.76       100\n",
      "   macro avg       0.76      0.75      0.76       100\n",
      "weighted avg       0.76      0.76      0.76       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer1 = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english')\n",
    "    )\n",
    "vectorizer2 = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english')\n",
    "    )\n",
    "vectorizer3 = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english')\n",
    "    )\n",
    "\n",
    "col_transformer = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"tfidf_1\", vectorizer1, \"Extracted_Sents\"),\n",
    "        (\"tfidf_2\", vectorizer2, \"Risks\"),\n",
    "        (\"tfidf_3\", vectorizer3, \"Organizations\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model = LogisticRegression(random_state=0, solver=\"liblinear\", C=10)\n",
    "clf_best = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"prep\", col_transformer),\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf_best.fit(X_train, y_train)\n",
    "y_pred = clf_best.predict(X_test)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using word vectors|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'link', 'Extracted_Sents', 'Risks', 'Organizations'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "# Remove Stopwords from train and test\n",
    "f = 'text_between_orgs'\n",
    "train_texts = [' '.join([t for t in text.split() if(t.lower() not in stop_words)]) for text in X_train['Extracted_Sents'] + X_train['Risks'] +  X_train['Organizations']]\n",
    "test_texts = [' '.join([t for t in text.split() if(t.lower() not in stop_words)]) for text in X_test['Extracted_Sents'] + X_test['Risks'] + X_test['Organizations']]\n",
    "\n",
    "# Get dataframes with text converted to spaCy vectors\n",
    "tr_df = pd.DataFrame([list(nlp(text).vector) for text in train_texts])\n",
    "te_df = pd.DataFrame([list(nlp(text).vector) for text in test_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 71.0\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        55\n",
      "           1       0.71      0.60      0.65        45\n",
      "\n",
      "    accuracy                           0.71       100\n",
      "   macro avg       0.71      0.70      0.70       100\n",
      "weighted avg       0.71      0.71      0.71       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "clf = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf.fit(tr_df, y_train)\n",
    "y_pred = clf.predict(te_df)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 67.0\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.78      0.72        55\n",
      "           1       0.67      0.53      0.59        45\n",
      "\n",
      "    accuracy                           0.67       100\n",
      "   macro avg       0.67      0.66      0.66       100\n",
      "weighted avg       0.67      0.67      0.66       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0)\n",
    "\n",
    "clf = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf.fit(tr_df, y_train)\n",
    "y_pred = clf.predict(te_df)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'link', 'Extracted_Sents', 'Risks', 'Organizations',\n",
       "       'Relationship_Tag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.DataFrame(columns=[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_btwn_substrings(test_str, sub1, sub2):\n",
    "    # getting index of substrings\n",
    "    idx1 = test_str.find(sub1)\n",
    "    idx2 = test_str.find(sub2)\n",
    "\n",
    "    # length of substring 1 is added to\n",
    "    # get string from next character\n",
    "    res = test_str[idx1 + len(sub1) + 1: idx2]\n",
    "    #print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ext_text, sub1, sub2 in training_set[['Extracted_Sents', 'Risks', 'Organizations']].itertuples(index=False):\n",
    "    cleaned_df.loc[len(cleaned_df.index)] = [get_text_btwn_substrings(ext_text, sub1, sub2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is more prevalent in developing countries, esp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stemming from the creation and coverup of poll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n June to wire fraud and violating the Clean A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and forfeited money judgments after pleading g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>that the firm conspired with two separate but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>which comes amid an epidemic of prescription ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>that FedEx illegally distributed controlled su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>distributed controlled substances and -- inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>responsibility for the legality of the content...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text\n",
       "0    is more prevalent in developing countries, esp...\n",
       "1    stemming from the creation and coverup of poll...\n",
       "2                                                     \n",
       "3    n June to wire fraud and violating the Clean A...\n",
       "4    and forfeited money judgments after pleading g...\n",
       "..                                                 ...\n",
       "493  that the firm conspired with two separate but ...\n",
       "494   which comes amid an epidemic of prescription ...\n",
       "495  that FedEx illegally distributed controlled su...\n",
       "496  distributed controlled substances and -- inclu...\n",
       "497  responsibility for the legality of the content...\n",
       "\n",
       "[498 rows x 1 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df[\"target\"] = training_set.Relationship_Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is more prevalent in developing countries, esp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stemming from the creation and coverup of poll...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n June to wire fraud and violating the Clean A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and forfeited money judgments after pleading g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>that the firm conspired with two separate but ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>which comes amid an epidemic of prescription ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>that FedEx illegally distributed controlled su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>distributed controlled substances and -- inclu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>responsibility for the legality of the content...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  target\n",
       "0    is more prevalent in developing countries, esp...       0\n",
       "1    stemming from the creation and coverup of poll...       1\n",
       "2                                                            1\n",
       "3    n June to wire fraud and violating the Clean A...       0\n",
       "4    and forfeited money judgments after pleading g...       1\n",
       "..                                                 ...     ...\n",
       "493  that the firm conspired with two separate but ...       1\n",
       "494   which comes amid an epidemic of prescription ...       1\n",
       "495  that FedEx illegally distributed controlled su...       1\n",
       "496  distributed controlled substances and -- inclu...       1\n",
       "497  responsibility for the legality of the content...       0\n",
       "\n",
       "[498 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling after generating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_df.drop('target', axis=1)\n",
    "y = cleaned_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>may not be able to do business with the U.S. g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>and deceive U.S. regulators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>in the corruption also approved spending more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>on U.S. emissions tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>to intentionally cheating on federal emissions...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text\n",
       "125  may not be able to do business with the U.S. g...\n",
       "466                        and deceive U.S. regulators\n",
       "270  in the corruption also approved spending more ...\n",
       "301                            on U.S. emissions tests\n",
       "18   to intentionally cheating on federal emissions..."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text'], dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 60.0\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67        55\n",
      "           1       0.58      0.42      0.49        45\n",
      "\n",
      "    accuracy                           0.60       100\n",
      "   macro avg       0.59      0.58      0.58       100\n",
      "weighted avg       0.60      0.60      0.59       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english')\n",
    "    )\n",
    "\n",
    "col_transformer = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"tfidf_1\", vectorizer, \"Text\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1)\n",
    "\n",
    "clf_best = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"prep\", col_transformer),\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf_best.fit(X_train, y_train)\n",
    "y_pred = clf_best.predict(X_test)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 61.0\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67        55\n",
      "           1       0.58      0.47      0.52        45\n",
      "\n",
      "    accuracy                           0.61       100\n",
      "   macro avg       0.60      0.60      0.60       100\n",
      "weighted avg       0.61      0.61      0.60       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english')\n",
    "    )\n",
    "\n",
    "col_transformer = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"tfidf_1\", vectorizer, \"Text\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model = LogisticRegression(random_state=0, solver=\"liblinear\", C=10)\n",
    "\n",
    "clf_best = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"prep\", col_transformer),\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf_best.fit(X_train, y_train)\n",
    "y_pred = clf_best.predict(X_test)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using word vectors|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "# Remove Stopwords from train and test\n",
    "f = 'Text'\n",
    "train_texts = [' '.join([t for t in text.split() if(t.lower() not in stop_words)]) for text in X_train[f]]\n",
    "test_texts = [' '.join([t for t in text.split() if(t.lower() not in stop_words)]) for text in X_test[f]]\n",
    "\n",
    "# Get dataframes with text converted to spaCy vectors\n",
    "tr_df = pd.DataFrame([list(nlp(text).vector) for text in train_texts])\n",
    "te_df = pd.DataFrame([list(nlp(text).vector) for text in test_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 57.99999999999999\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.64        55\n",
      "           1       0.54      0.44      0.49        45\n",
      "\n",
      "    accuracy                           0.58       100\n",
      "   macro avg       0.57      0.57      0.57       100\n",
      "weighted avg       0.57      0.58      0.57       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler(random_state=0)\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "clf = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"oversampling\", oversample),\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf.fit(tr_df, y_train)\n",
    "y_pred = clf.predict(te_df)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 57.99999999999999\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.64        55\n",
      "           1       0.54      0.44      0.49        45\n",
      "\n",
      "    accuracy                           0.58       100\n",
      "   macro avg       0.57      0.57      0.57       100\n",
      "weighted avg       0.57      0.58      0.57       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler(random_state=0)\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "clf = imb_Pipeline(\n",
    "    steps=[\n",
    "        (\"oversampling\", oversample),\n",
    "        (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf.fit(tr_df, y_train)\n",
    "y_pred = clf.predict(te_df)\n",
    "\n",
    "acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "print(f\"Accuracy score: {acc*100}\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all the text columns with separate TF-IDF vectorizers yields an **Accuracy of 0.77 with a weighted F1-Score of 0.76.**. We see a drop in performance when using word vectors as the Accuracy drops to 0.71.\n",
    "\n",
    "After creating new features by extracting the text between the given entities, we see a further drop in performance with the best results reaching only an **Accuracy of 0.61.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8239ba0ff96be68a749984a1d0f0fdb6158c4e27c47b22616c2f5e2eb3d022cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
